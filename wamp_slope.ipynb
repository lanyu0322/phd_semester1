{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of wamp_less_than_0.0035.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "xTXFO43YqURR"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lanyu0322/phd_semester1/blob/master/wamp_slope.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4Zk3vIRoIHQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import time\n",
        "import statistics\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.ndimage.filters import uniform_filter as uf\n",
        "from scipy.optimize import least_squares\n",
        "\n",
        "#plt.style.use(\"bmh\")\n",
        "plt.rcParams[\"figure.figsize\"] = [7, 5]\n",
        "import glob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoFqbU5LnSAs",
        "colab_type": "code",
        "outputId": "18039703-2ddd-4ed3-a18b-7dd4ed18b935",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTXFO43YqURR",
        "colab_type": "text"
      },
      "source": [
        "# Define 4 pop model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8-CwftQqYAU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -- read in the average weekend counts\n",
        "fname = os.path.join(\"drive\", \"My Drive\", \"lwir\", \"data\", \"nycdot\", \n",
        "                     \"avg_weekend_ts.feather\")\n",
        "weekend = uf(pd.read_feather(fname)[\"avg_counts\"].values, 8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmhBxrSwqYXo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -- read temp and humidity data\n",
        "tname = os.path.join(\"drive\", \"My Drive\", \"lwir\", \"data\", \"4_pop_fit\", \n",
        "                     \"temp_humidity.csv\")\n",
        "temp = pd.read_csv(tname)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czISfkH4qYyW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -- define gaussian\n",
        "def gauss(xarr, x0, sig, scl):\n",
        "  \"\"\" Create a 1D Gaussian \"\"\"\n",
        "  \n",
        "  amp = scl / (sig * np.sqrt(2.0 * np.pi))\n",
        "  val = -0.5 * ((xarr - x0) / sig)**2\n",
        "  \n",
        "  return amp * np.exp(val)\n",
        "\n",
        "\n",
        "# -- define the model\n",
        "def pop_model(param, xval):\n",
        "\n",
        "  # -- determine which model is being used from length of param array\n",
        "  nparam = len(param)\n",
        "\n",
        "  # -- 3 population model\n",
        "  if nparam == 10:\n",
        "    m1, m2, m3, sd1, sd2, sd3, scl1, scl2, scl3, off = param\n",
        "    wamp = 0.0\n",
        "\n",
        "  # -- 4 population model\n",
        "  elif nparam == 11:\n",
        "    m1, m2, m3, sd1, sd2, sd3, scl1, scl2, scl3, wamp, off = param\n",
        "\n",
        "  # -- ill-defined param array\n",
        "  else:\n",
        "    print(\"Nparam must be 10 (3pop) or 11 (4pop) model!\")\n",
        "    return None\n",
        "\n",
        "  model = gauss(xval, m1, sd1, scl1) + gauss(xval, m2, sd2, scl2) + \\\n",
        "    gauss(xval, m3, sd3, scl3) + wamp * wendvals + off\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "# -- define model error\n",
        "def res(param, xval, yval):\n",
        "\n",
        "  return yval - pop_model(param, xval)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzC9NO-iqdOM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -- set inital guess\n",
        "avgs  = [35, 47, 70] \n",
        "sigs  = [3, 3, 3]\n",
        "scls  = [5, 5, 5]\n",
        "off   = [0.5]\n",
        "wamp = [6]\n",
        "param = avgs + sigs + scls + wamp + off\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KppNJFHWpWQ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -- set fit and model parameters and \n",
        "wendvals = weekend\n",
        "xval_final = np.arange(96)\n",
        "bounds_lo = [24., 44., 64., 2.0, 2.0, 2.0, 0, 0, 0, 0, -np.inf]\n",
        "bounds_hi = [44., 64., 80., 8., 8., 8., np.inf, np.inf, np.inf, np.inf, np.inf]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROOiJE9Es4qZ",
        "colab_type": "text"
      },
      "source": [
        "# Get time series data for each camera each day"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxO8lH-uJIjH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -- read the outliers have no three peak\n",
        "bind = [175, 409, 172, 176, 165, 170, 173, 360, 501, 537, 545, 795, 547, 845, \n",
        "        845, 899, 891, 934, 940, 970, 475, 989, 791, 988, 291, 530, 909, 248, \n",
        "        500, 177, 968, 517, 805, 932, 432, 452, 847, 790, 969, 841, 446, 893, \n",
        "        715]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baYgQ_rwPrZZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -- read multi_files and combine them together\n",
        "path = r'drive/My Drive/lwir/data/nycdot/counts_wd_cam'\n",
        "all_files = glob.glob(path + \"/*.feather\")\n",
        "\n",
        "li = []\n",
        "cnum = []\n",
        "\n",
        "for filename in all_files:\n",
        "  valid = True\n",
        "  for b_id in bind:\n",
        "    if (str(b_id) in filename):\n",
        "      valid = False\n",
        "      break\n",
        "  if valid:\n",
        "    df = pd.read_feather(filename)\n",
        "    cum = filename.split(\"_\")[-1].split(\"_\")[0]\n",
        "    li.append(df)\n",
        "    cnum.append(cum)\n",
        "\n",
        "frame = pd.concat(li, axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBswTUXStNRa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -- create day and time column\n",
        "frame[\"day\"] = frame[\"date\"].dt.date\n",
        "frame[\"time\"] = frame[\"date\"].dt.time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFgBjHEm9PT1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -- get available date data\n",
        "day = frame.groupby(\"day\").count().reset_index()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8QoHIl5tztb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -- groupby day and get the values\n",
        "ff1a = frame.groupby(\"time\")\n",
        "\n",
        "avg_frame = []\n",
        "for ind, gp in ff1a:\n",
        "  avg_frame.append(gp[\"count\"].values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgYROPtdykjD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -- replace nans to nearest average counts\n",
        "avg_frame = pd.DataFrame(avg_frame)\n",
        "fnan = avg_frame.ffill()\n",
        "bnan = avg_frame.bfill()\n",
        "avg_count = 0.5*(fnan + bnan).T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmmzot5i8UhI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -- add date for groupby\n",
        "def new_sratio(sratio):\n",
        "  sratio_day = []\n",
        "  for index, row in sratio.iterrows():\n",
        "   \n",
        "    day_index = index % 31\n",
        "    new_row = []\n",
        "    new_row.append(row[\"sratio\"])\n",
        "    new_row.append(day[\"day\"].iloc[day_index]) #add a new sublist to each sratio\n",
        "    sratio_day.append(new_row)\n",
        "\n",
        "  return sratio_day"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tShsRwnH3hgM",
        "colab_type": "text"
      },
      "source": [
        "# 1a. For a given day, calculate the sratio for each camera and average."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lw0H9dI7WHZn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -- transfer to dataframe \n",
        "avg_la = pd.DataFrame(avg_count)\n",
        "\n",
        "\n",
        "cam_avg = []\n",
        "for i in range(115):\n",
        "  if i == 0:\n",
        "    avg_cam = avg_la.iloc[0:31].mean()\n",
        "  else:\n",
        "    ii = i * 31\n",
        "    jj = ii + 31\n",
        "    avg_cam = avg_la.iloc[ii:jj].mean()\n",
        "  cam_avg.append(avg_cam)\n",
        "  \n",
        "cam_avg = pd.DataFrame(cam_avg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNM3f1vRuD2Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -- set fit and model parameters and \n",
        "wendvals = weekend\n",
        "xval_final = np.arange(96)\n",
        "bounds_lo = [24., 44., 64., 2.0, 2.0, 2.0, 0, 0, 0, 0, -np.inf]\n",
        "bounds_hi = [44., 64., 80., 8., 8., 8., np.inf, np.inf, np.inf, np.inf, np.inf]\n",
        "# -- optimize\n",
        "plsq = []\n",
        "for ii in range(len(cam_avg)):\n",
        "  #print(\"working on day {0}\".format(ii))\n",
        "\n",
        "  plsq.append(least_squares(res, param, bounds=(bounds_lo, bounds_hi), \n",
        "                            args=(xval_final, cam_avg.iloc[ii])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ot4bo8gbxWr4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -- put fit results into DataFrame\n",
        "result_1a = pd.DataFrame(plsq)[\"x\"].values\n",
        "\n",
        "df1a = pd.DataFrame(np.vstack(result_1a), \n",
        "                     columns=[\"m1\", \"m2\", \"m3\", \"sd1\", \"sd2\", \"sd3\", \n",
        "                              \"scl1\", \"scl2\", \"scl3\", \"wamp\", \"off\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-2Jqzg-Bfu2",
        "colab_type": "text"
      },
      "source": [
        "# Get the dropped camera ID"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnWB0WgoLD5Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -- add camera number\n",
        "df1a[\"cnum\"] = cnum\n",
        "import re\n",
        "import statsmodels.formula.api as sm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QIoW6ORd7cw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -- read in the weekday counts\n",
        "camera_fname = os.path.join(\"drive\", \"My Drive\", \"lwir\", \"data\", \"nycdot\", \n",
        "                            \"cams_ft_wd.feather\")\n",
        "camera = pd.read_feather(camera_fname)\n",
        "\n",
        "# -- read cam id for outliers that have no three peak\n",
        "bind = [175, 409, 172, 176, 165, 170, 173, 360, 501, 537, 545, 795, 547, 845, \n",
        "        845, 899, 891, 934, 940, 970, 475, 989, 791, 988, 291, 530, 909, 248, \n",
        "        500, 177, 968, 517, 805, 932, 432, 452, 847, 790, 969, 841, 446, 893, \n",
        "        715]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0fYouQmhRfH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -- define add date\n",
        "\n",
        "def add_date(count):\n",
        "  count_day = []\n",
        "  for index, row in count.iterrows():\n",
        "   \n",
        "    day_index = index % 31\n",
        "    new_row = []\n",
        "    for i in range(len(row)):\n",
        "      new_row.append(row[i])\n",
        "    new_row.append(day[\"day\"].iloc[day_index]) #add a new sublist to each row\n",
        "    count_day.append(new_row)\n",
        "\n",
        "  return count_day"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riAwzdBGJLMY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # coefs = []\n",
        "# # wcuts = np.linspace(0.00275, 0.0040, 50)\n",
        "# # for wcut in wcuts:\n",
        "# # # -- select cams with wamp < wcut\n",
        "\n",
        "#   drop_camera = df1a[df1a[\"wamp\"] > 0.00275]\n",
        "#   drop_cam = drop_camera[drop_camera[\"wamp\"] > 0.0040]\n",
        "#   dcnum = drop_cam[\"cnum\"]\n",
        "#   # -- keep only numeric\n",
        "#   drop_id = dcnum.str.replace(r'[^0-9]+', '')\n",
        "#   id = []\n",
        "#   for e in drop_id:\n",
        "#     res = e[1:]\n",
        "#     id.append(res)\n",
        "#   id = pd.DataFrame(id)\n",
        "#   id[\"id\"] = id\n",
        "#   # -- get the lat/lon of the dropped cameras\n",
        "#   camera[\"cam_id\"] = camera[\"cam_id\"].astype(str)\n",
        "#   cam_id = camera.merge(id, left_on=\"cam_id\", right_on=\"id\")\n",
        "#   dcnum = pd.DataFrame(dcnum)\n",
        "#   bad_camera = []\n",
        "#   for v in dcnum.values.tolist():\n",
        "#     bad_camera.append(int(v.pop().split(\".\")[0]))\n",
        "#     final_bad_cam = list(set(bind + bad_camera))\n",
        "#   # -- read multi_files and combine them together\n",
        "#   path = r'drive/My Drive/lwir/data/nycdot/counts_wd_cam'\n",
        "#   all_files = glob.glob(path + \"/*.feather\")\n",
        "\n",
        "#   cam = []\n",
        "#   num = []\n",
        "\n",
        "#   for filename in all_files:\n",
        "#     valid = True\n",
        "#     for b_id in final_bad_cam:\n",
        "#       if (str(b_id) in filename):\n",
        "#         valid = False\n",
        "#         break\n",
        "#     if valid:\n",
        "#       df0 = pd.read_feather(filename)\n",
        "#       cum = filename.split(\"_\")[-1].split(\"_\")[0]\n",
        "#       cam.append(df0)\n",
        "#       num.append(cum)\n",
        "\n",
        "#   frame_drop = pd.concat(cam, axis=0, ignore_index=True)\n",
        "#   # -- create day and time column\n",
        "#   frame_drop[\"day\"] = frame_drop[\"date\"].dt.date\n",
        "#   frame_drop[\"time\"] = frame_drop[\"date\"].dt.time\n",
        "#   # -- get available date data\n",
        "#   day_drop = frame_drop.groupby(\"day\").count().reset_index()  \n",
        "#   # -- groupby day and get the values\n",
        "\n",
        "#   fft = frame_drop.groupby(\"time\")\n",
        "\n",
        "#   avg_frame_drop = []\n",
        "#   for ind, gp in fft:\n",
        "#     avg_frame_drop.append(gp[\"count\"].values)\n",
        "#   # -- replace nans to nearest average counts\n",
        "#   avg_frame_drop = pd.DataFrame(avg_frame_drop)\n",
        "#   fnan_drop = avg_frame_drop.ffill()\n",
        "#   bnan_drop = avg_frame_drop.bfill()\n",
        "#   avg_count_drop = 0.5*(fnan_drop + bnan_drop).T\n",
        "#   # -- get the counts\n",
        "#   avg_2b = avg_count_drop.values.copy()\n",
        "#   # -- standardized data\n",
        "#   avg_2b_m = avg_2b.mean(axis=1, keepdims=True)\n",
        "#   avg_2b_std = avg_2b.std(axis=1, keepdims=True)\n",
        "#   avg_2b_st = (avg_2b - avg_2b_m) / (avg_2b_std + (avg_2b_std == 0))\n",
        "#   avg_2b_st = pd.DataFrame(avg_2b_st)\n",
        "#   # -- get available date data\n",
        "#   day = frame.groupby(\"day\").count().reset_index()\n",
        "#   # -- add date for st counts\n",
        "#   avg_2b_date = pd.DataFrame(add_date(avg_2b_st))\n",
        "#   # -- rename dataframe 96 to day\n",
        "#   avg_2b_date = avg_2b_date.rename(columns = {96:'day'})\n",
        "#   # -- get avg_st counts\n",
        "#   avg_std_date = avg_2b_date.groupby(\"day\").mean()\n",
        "\n",
        "#   # -- optimize\n",
        "#   wendvals = weekend\n",
        "#   xval_final = np.arange(96)\n",
        "#   bounds_lo = [24., 44., 64., 2.0, 2.0, 2.0, 0, 0, 0, 0, -np.inf]\n",
        "#   bounds_hi = [44., 64., 80., 8., 8., 8., np.inf, np.inf, np.inf, np.inf, np.inf]\n",
        "\n",
        "#   plsq_2b = []\n",
        "#   for ii in range(len(avg_std_date)):\n",
        "#     plsq_2b.append(least_squares(res, param, bounds=(bounds_lo, bounds_hi), \n",
        "#                               args=(xval_final, avg_std_date.iloc[ii])))\n",
        "    \n",
        "# #   # -- put fit results into DataFrame\n",
        "# #   result_2b = pd.DataFrame(plsq_2b)[\"x\"].values\n",
        "# #   df2b = pd.DataFrame(np.vstack(result_2b), \n",
        "# #                       columns=[\"m1\", \"m2\", \"m3\", \"sd1\", \"sd2\", \"sd3\", \n",
        "# #                               \"scl1\", \"scl2\", \"scl3\", \"wamp\", \"off\"])\n",
        "# #   # -- calculate sratio \n",
        "# #   df2b[\"sratio\"] = df2b[\"scl2\"] / (0.5 * (df2b[\"scl1\"] + df2b[\"scl3\"]))\n",
        "# #   # -- add date column\n",
        "# #   sratio_2b = pd.DataFrame(new_sratio(df2b))\n",
        "# #   sratio_2b[\"wamp\"] = df2b[\"wamp\"]\n",
        "# #   sratio_2b[\"scl1\"] = df2b[\"scl1\"]\n",
        "# #   sratio_2b[\"scl2\"] = df2b[\"scl2\"]\n",
        "# #   sratio_2b[\"scl3\"] = df2b[\"scl3\"]\n",
        "# #   sratio_2b.columns = [\"sratio\", \"date\", \"wamp\", \"scl1\", \"scl2\", \"scl3\"]\n",
        "# #   # -- subset humidity and temp to our research period\n",
        "# #   sratio_2b[\"date\"] = sratio_2b[\"date\"].astype(str)\n",
        "# #   temp_day_2b = sratio_2b.merge(temp, left_on=\"date\", right_on=\"day\")\n",
        "# #   # -- first build the model\n",
        "# #   model = sm.ols(\"sratio ~ temp\", data=temp_day_2b)\n",
        "# #   # -- now fit the model to the data\n",
        "# #   result = model.fit()\n",
        "# #   coefs.append(result.coef_[0])\n",
        "\n",
        "# # plot(wcuts, coefs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkVc8iFRhXVe",
        "colab_type": "text"
      },
      "source": [
        "# 从这里开始"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KX0HJhBZctc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drop_camera = df1a[df1a[\"wamp\"] > 0.00275]\n",
        "drop_cam = drop_camera[drop_camera[\"wamp\"] > 0.0040]\n",
        "dcnum = drop_cam[\"cnum\"]\n",
        "  # -- keep only numeric\n",
        "drop_id = dcnum.str.replace(r'[^0-9]+', '')\n",
        "id = []\n",
        "for e in drop_id:\n",
        "  res = e[1:]\n",
        "  id.append(res)\n",
        "id = pd.DataFrame(id)\n",
        "id[\"id\"] = id\n",
        "  # -- get the lat/lon of the dropped cameras\n",
        "camera[\"cam_id\"] = camera[\"cam_id\"].astype(str)\n",
        "cam_id = camera.merge(id, left_on=\"cam_id\", right_on=\"id\")\n",
        "dcnum = pd.DataFrame(dcnum)\n",
        "bad_camera = []\n",
        "for v in dcnum.values.tolist():\n",
        "  bad_camera.append(int(v.pop().split(\".\")[0]))\n",
        "  final_bad_cam = list(set(bind + bad_camera))\n",
        "  # -- read multi_files and combine them together\n",
        "path = r'drive/My Drive/lwir/data/nycdot/counts_wd_cam'\n",
        "all_files = glob.glob(path + \"/*.feather\")\n",
        "\n",
        "cam = []\n",
        "num = []\n",
        "\n",
        "for filename in all_files:\n",
        "  valid = True\n",
        "  for b_id in final_bad_cam:\n",
        "    if (str(b_id) in filename):\n",
        "      valid = False\n",
        "      break\n",
        "  if valid:\n",
        "    df0 = pd.read_feather(filename)\n",
        "    cum = filename.split(\"_\")[-1].split(\"_\")[0]\n",
        "    cam.append(df0)\n",
        "    num.append(cum)\n",
        "\n",
        "frame_drop = pd.concat(cam, axis=0, ignore_index=True)\n",
        "  # -- create day and time column\n",
        "frame_drop[\"day\"] = frame_drop[\"date\"].dt.date\n",
        "frame_drop[\"time\"] = frame_drop[\"date\"].dt.time\n",
        "  # -- get available date data\n",
        "day_drop = frame_drop.groupby(\"day\").count().reset_index()  \n",
        "  # -- groupby day and get the values\n",
        "\n",
        "fft = frame_drop.groupby(\"time\")\n",
        "\n",
        "avg_frame_drop = []\n",
        "for ind, gp in fft:\n",
        "  avg_frame_drop.append(gp[\"count\"].values)\n",
        "  # -- replace nans to nearest average counts\n",
        "avg_frame_drop = pd.DataFrame(avg_frame_drop)\n",
        "fnan_drop = avg_frame_drop.ffill()\n",
        "bnan_drop = avg_frame_drop.bfill()\n",
        "avg_count_drop = 0.5*(fnan_drop + bnan_drop).T\n",
        "  # -- get the counts\n",
        "avg_2b = avg_count_drop.values.copy()\n",
        "  # -- standardized data\n",
        "avg_2b_m = avg_2b.mean(axis=1, keepdims=True)\n",
        "avg_2b_std = avg_2b.std(axis=1, keepdims=True)\n",
        "avg_2b_st = (avg_2b - avg_2b_m) / (avg_2b_std + (avg_2b_std == 0))\n",
        "avg_2b_st = pd.DataFrame(avg_2b_st)\n",
        "  # -- get available date data\n",
        "day = frame.groupby(\"day\").count().reset_index()\n",
        "  # -- add date for st counts\n",
        "avg_2b_date = pd.DataFrame(add_date(avg_2b_st))\n",
        "  # -- rename dataframe 96 to day\n",
        "avg_2b_date = avg_2b_date.rename(columns = {96:'day'})\n",
        "  # -- get avg_st counts\n",
        "avg_std_date = avg_2b_date.groupby(\"day\").mean()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOo519ZRgnpB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "c9b8fffe-5735-4c4e-92f9-aa911f80fb2b"
      },
      "source": [
        "  # -- optimize\n",
        "wendvals = weekend\n",
        "xval_final = np.arange(96)\n",
        "bounds_lo = [24., 44., 64., 2.0, 2.0, 2.0, 0, 0, 0, 0, -np.inf]\n",
        "bounds_hi = [44., 64., 80., 8., 8., 8., np.inf, np.inf, np.inf, np.inf, np.inf]\n",
        "\n",
        "plsq_2b = []\n",
        "for ii in range(len(avg_std_date)):\n",
        "  print(\"working on day {0}\".format(ii))\n",
        "  plsq_2b.append(least_squares(res, param, bounds=(bounds_lo, bounds_hi), args=(xval_final, \n",
        "                                                                                avg_std_date.iloc[ii])))"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "working on day 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-127-59b8995700f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"working on day {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   plsq_2b.append(least_squares(res, param, bounds=(bounds_lo, bounds_hi), args=(xval_final, \n\u001b[0;32m---> 10\u001b[0;31m                                                                                 avg_std_date.iloc[ii])))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/optimize/_lsq/least_squares.py\u001b[0m in \u001b[0;36mleast_squares\u001b[0;34m(fun, x0, jac, bounds, method, ftol, xtol, gtol, x_scale, loss, f_scale, diff_step, tr_solver, tr_options, jac_sparsity, max_nfev, verbose, args, kwargs)\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0mx0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_strictly_feasible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m     \u001b[0mf0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mf0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/optimize/_lsq/least_squares.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 802\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'trf'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'str' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q72I2jythF3R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}